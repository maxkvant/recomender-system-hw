{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7x9siv3te0jg25t42jrnl"
   },
   "source": [
    "### Матричные факторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "poh2izz6wxde7o995t9fx"
   },
   "source": [
    "В данной работе вам предстоит познакомиться с практической стороной матричных разложений.\n",
    "Работа поделена на 4 задания:\n",
    "1. Вам необходимо реализовать SVD разложения используя SGD на explicit данных\n",
    "2. Вам необходимо реализовать матричное разложения используя ALS на implicit данных\n",
    "3. Вам необходимо реализовать матричное разложения используя BPR(pair-wise loss) на implicit данных\n",
    "4. Вам необходимо реализовать матричное разложения используя WARP(list-wise loss) на implicit данных\n",
    "\n",
    "Мягкий дедлайн 28 Сентября (пишутся замечания, выставляется оценка, есть возможность исправить до жесткого дедлайна)\n",
    "\n",
    "Жесткий дедлайн 5 Октября (Итоговая проверка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "vyus0b4sj8sz7crmzthe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightfm\n",
      "  Downloading lightfm-1.15.tar.gz (302 kB)\n",
      "\u001b[K     |████████████████████████████████| 302 kB 846 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.19.1\n",
      "  Using cached numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting scipy==1.4.1\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Collecting requests==2.22.0\n",
      "  Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
      "Collecting idna==2.8\n",
      "  Using cached idna-2.8-py2.py3-none-any.whl (58 kB)\n",
      "Collecting chardet==3.0.4\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting urllib3==1.25.10\n",
      "  Using cached urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "Collecting certifi==2020.6.20\n",
      "  Using cached certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
      "Building wheels for collected packages: lightfm\n",
      "  Building wheel for lightfm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lightfm: filename=lightfm-1.15-cp37-cp37m-linux_x86_64.whl size=705693 sha256=dc808e29c69762829a4c63dc5520debe54d68fadb53ab634c2f20f518bce5dd3\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/f0/cd/a5/b07914aa223c05ed61880d4c59f64a7febf117dbd2c2cbcf49\n",
      "Successfully built lightfm\n",
      "Installing collected packages: certifi, chardet, idna, numpy, urllib3, requests, scipy, lightfm\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "torchvision 0.5.0 requires torch==1.4.0, but you'll have torch 1.6.0 which is incompatible.\n",
      "dvc 1.4.0 requires networkx<2.5,>=2.1, but you'll have networkx 2.5 which is incompatible.\u001b[0m\n",
      "Successfully installed certifi-2020.6.20 chardet-3.0.4 idna-2.8 lightfm-1.15 numpy-1.19.1 requests-2.22.0 scipy-1.4.1 urllib3-1.25.10\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/urllib3-1.25.10.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/chardet-3.0.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/certifi-2020.6.20.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/lightfm-1.15.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/requests already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/scipy-1.4.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/idna-2.8.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/lightfm already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/numpy-1.19.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/idna already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/requests-2.22.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/chardet already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/py-env/platform-env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting implicit\n",
      "  Downloading implicit-0.4.4.tar.gz (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 790 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.19.1\n",
      "  Using cached numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting scipy==1.4.1\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Collecting tqdm==4.45.0\n",
      "  Using cached tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
      "Building wheels for collected packages: implicit\n",
      "  Building wheel for implicit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for implicit: filename=implicit-0.4.4-cp37-cp37m-linux_x86_64.whl size=3410276 sha256=d8da4767d661d85399dbd30a929a59f95cb12360b80052e0db8ed51b75bd3b85\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/44/7e/7d/a17324ea207cfbe76aca878b5b8ca0aa932cf55d163329be37\n",
      "Successfully built implicit\n",
      "Installing collected packages: numpy, scipy, tqdm, implicit\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "torchvision 0.5.0 requires torch==1.4.0, but you'll have torch 1.6.0 which is incompatible.\n",
      "dvc 1.4.0 requires networkx<2.5,>=2.1, but you'll have networkx 2.5 which is incompatible.\u001b[0m\n",
      "Successfully installed implicit-0.4.4 numpy-1.19.1 scipy-1.4.1 tqdm-4.45.0\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/implicit-0.4.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/scipy-1.4.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/tqdm-4.45.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/numpy-1.19.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/implicit already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/py-env/platform-env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install lightfm\n",
    "%pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "ghxig1yb5c8hxkvvin783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/work/resources/hse_recsys2020/HomeWorks\n"
     ]
    }
   ],
   "source": [
    "%cd hse_recsys2020/HomeWorks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "ivgv38v9dqfpn04253y2wo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1::F::1::10::48067', '2::M::56::16::70072', '3::M::25::15::55117', '4::M::45::7::02460', '5::M::25::20::55455', '6::F::50::9::55117', '7::M::35::1::06810', '8::M::25::12::11413', '9::M::25::17::61614', '10::F::35::1::95370']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: .: Is a directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from subprocess import Popen\n",
    "from subprocess import PIPE\n",
    "\n",
    "stdout, stderr = Popen([\"cat\", \"ml-1m/users.dat\", \".\"], stdout=PIPE, stderr=PIPE).communicate()\n",
    "print(stdout.decode().split(\"\\n\")[:10])\n",
    "print(stderr.decode(), file=sys.stderr)\n",
    "\n",
    "del stdout\n",
    "del stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "uo77drb4rfec73uqtsvrqr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/work/resources/hse_recsys2020/HomeWorks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "0peiasoja3ibcpgo4rg54p6"
   },
   "outputs": [],
   "source": [
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from lightfm.datasets import fetch_movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "0g069lyhg3narh5q7a837qd"
   },
   "source": [
    "В данной работе мы будем работать с explicit датасетом movieLens, в котором представленны пары user_id movie_id и rating выставленный пользователем фильму\n",
    "\n",
    "Скачать датасет можно по ссылке https://grouplens.org/datasets/movielens/1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "auflwz4v8cc1knvzokbtf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ml-1m.zip', <http.client.HTTPMessage at 0x7fce0d60f290>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "filename = 'ml-1m.zip'\n",
    "urllib.request.urlretrieve('http://files.grouplens.org/datasets/movielens/ml-1m.zip', 'ml-1m.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellId": "v8d5a1ezizr58tdy8hbl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting : 100%|██████████| 5/5 [00:03<00:00,  1.30it/s]\n",
      "/py-env/platform-env/lib/python3.7/site-packages/ml_kernel/kernel.py:405: UserWarning: The following variables cannot be serialized: zf\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "fname = './ml-1m.zip'\n",
    "path = './'\n",
    "\n",
    "with zipfile.ZipFile(fname, 'r') as zf:\n",
    "    for entry in tqdm(zf.infolist(), desc='Extracting '):\n",
    "        try:\n",
    "            zf.extract(entry, path)\n",
    "        except zipfile.error as e:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "ummoys12jiltues22vxeif"
   },
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', delimiter='::', header=None, \n",
    "        names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "        usecols=['user_id', 'movie_id', 'rating', 'timestamp'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "gvkosuj0j5usl3kqsz60oo"
   },
   "outputs": [],
   "source": [
    "movie_info = pd.read_csv('ml-1m/movies.dat', delimiter='::', header=None, \n",
    "        names=['movie_id', 'name', 'category'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "jhta3t1clfhaa820zo4v"
   },
   "source": [
    "Explicit данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "9y2gcacsxs97mdu7pcep7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>978302039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>978300719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "      <td>978301368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0        1      1193       5  978300760\n",
       "1        1       661       3  978302109\n",
       "2        1       914       3  978301968\n",
       "3        1      3408       4  978300275\n",
       "4        1      2355       5  978824291\n",
       "5        1      1197       3  978302268\n",
       "6        1      1287       5  978302039\n",
       "7        1      2804       5  978300719\n",
       "8        1       594       4  978302268\n",
       "9        1       919       4  978301368"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "gxpr59wv4ftmtguwipbzks"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7275isr1x872xpddjvvu06"
   },
   "source": [
    "Для того, чтобы преобразовать текущий датасет в Implicit, давайте считать что позитивная оценка это оценка >=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "hkl04vqa95g4abjo13t8xh"
   },
   "outputs": [],
   "source": [
    "implicit_ratings = ratings.loc[(ratings['rating'] >= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "7sshb2kggz58payzdr6rls"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>978302039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "      <td>978300719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "      <td>978301368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "      <td>978301752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2398</td>\n",
       "      <td>4</td>\n",
       "      <td>978302281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  movie_id  rating  timestamp\n",
       "0         1      1193       5  978300760\n",
       "3         1      3408       4  978300275\n",
       "4         1      2355       5  978824291\n",
       "6         1      1287       5  978302039\n",
       "7         1      2804       5  978300719\n",
       "8         1       594       4  978302268\n",
       "9         1       919       4  978301368\n",
       "10        1       595       5  978824268\n",
       "11        1       938       4  978301752\n",
       "12        1      2398       4  978302281"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "195wmax89q28sb5616zom7"
   },
   "source": [
    "Удобнее работать с sparse матричками, давайте преобразуем DataFrame в CSR матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellId": "ddi5wt3wxx8qa4guzv58t"
   },
   "outputs": [],
   "source": [
    "users = implicit_ratings[\"user_id\"]\n",
    "movies = implicit_ratings[\"movie_id\"]\n",
    "user_item = sp.coo_matrix((np.ones_like(users), (users, movies)))\n",
    "user_item_t_csr = user_item.T.tocsr()\n",
    "user_item_csr = user_item.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "utwjq22u8joqv8tpxasajb"
   },
   "source": [
    "В качестве примера воспользуемся ALS разложением из библиотеки implicit\n",
    "\n",
    "Зададим размерность латентного пространства равным 64, это же определяет размер user/item эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "jqqfhcg6yhsnsmmvnfglg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "#!L\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=64, iterations=100, calculate_training_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "ki8yj07igzn1n3wohhcw0z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3953x6041 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 575281 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "user_item_t_csr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "im57amfzc2obblzgjtwj"
   },
   "source": [
    "В качестве loss здесь всеми любимый RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellId": "18x12yxav1vclfteiqufa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45888c41864d4027a85e99d717167020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "msg_type": null,
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!L\n",
    "\n",
    "model.fit(user_item_t_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellId": "nu5gnap5g3meotsea1i2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<implicit.als.AlternatingLeastSquares at 0x7ff60ad9c9d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "hxx0lb8an2p3sk69fcq36"
   },
   "source": [
    "Построим похожие фильмы по 1 movie_id = Истории игрушек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellId": "fb1phm448whv8m7eynemw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                name                      category\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4         5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellId": "jox4wc8ew6l2ls13oyi5"
   },
   "outputs": [],
   "source": [
    "get_similars = lambda item_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                        for x in model.similar_items(item_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "h3bgpc0pj1wofd5n7ueymc"
   },
   "source": [
    "Как мы видим, симилары действительно оказались симиларами.\n",
    "\n",
    "Качество симиларов часто является хорошим способом проверить качество алгоритмов.\n",
    "\n",
    "P.S. Если хочется поглубже разобраться в том как разные алгоритмы формируют разные латентные пространства, рекомендую загружать полученные вектора в tensorBoard и смотреть на сформированное пространство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellId": "t34jmv9ak9qebl3g9qj10h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '33    Babe (1995)',\n",
       " '2315    Babe: Pig in the City (1998)',\n",
       " '584    Aladdin (1992)',\n",
       " '2252    Pleasantville (1998)',\n",
       " '2692    Iron Giant, The (1999)',\n",
       " '1526    Hercules (1997)',\n",
       " '3817    Went to Coney Island on a Mission From God... ...']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "pcb9s0rdjs7sozjdbkc3n"
   },
   "source": [
    "Давайте теперь построим рекомендации для юзеров\n",
    "\n",
    "Как мы видим юзеру нравится фантастика, значит и в рекомендациях ожидаем увидеть фантастику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellId": "95738xy4snshfvdzlt3c7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2    Grumpier Old Men (1995)',\n",
       " '3381    Grumpy Old Men (1993)',\n",
       " '819    First Wives Club, The (1996)',\n",
       " '516    Robin Hood: Men in Tights (1993)',\n",
       " '184    Nine Months (1995)',\n",
       " '234    Forget Paris (1995)',\n",
       " '1619    Bean (1997)',\n",
       " '482    Life with Mikey (1993)',\n",
       " \"1420    McHale's Navy (1997)\",\n",
       " '1369    My Fellow Americans (1996)']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellId": "46h61a74g57shp6pr9uzh"
   },
   "outputs": [],
   "source": [
    "get_user_history = lambda user_id, implicit_ratings : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() \n",
    "                                            for x in implicit_ratings[implicit_ratings[\"user_id\"] == user_id][\"movie_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellId": "hihmje4mg86szf4hnu5t7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3399    Hustler, The (1961)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1196    Alien (1979)',\n",
       " '1023    Die Hard (1988)',\n",
       " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '1959    Saving Private Ryan (1998)',\n",
       " '476    Jurassic Park (1993)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '1885    Rocky (1976)',\n",
       " '1081    E.T. the Extra-Terrestrial (1982)',\n",
       " '3349    Thelma & Louise (1991)',\n",
       " '3633    Mad Max (1979)',\n",
       " '2297    King Kong (1933)',\n",
       " '1366    Jaws (1975)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '2623    Run Lola Run (Lola rennt) (1998)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1220    Terminator, The (1984)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_history(4, implicit_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3fwsggybpnluc6dgu43sm"
   },
   "source": [
    "Получилось! \n",
    "\n",
    "Мы действительно порекомендовали пользователю фантастику и боевики, более того встречаются продолжения тех фильмов, которые он высоко оценил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellId": "loum23k44qja0ntio2ix"
   },
   "outputs": [],
   "source": [
    "get_recommendations = lambda user_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                               for x in model.recommend(user_id, user_item_csr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellId": "sn0l195we81v8iy01abb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['585    Terminator 2: Judgment Day (1991)',\n",
       " '1271    Indiana Jones and the Last Crusade (1989)',\n",
       " '1182    Aliens (1986)',\n",
       " '1284    Butch Cassidy and the Sundance Kid (1969)',\n",
       " '1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '2502    Matrix, The (1999)',\n",
       " '1892    Rain Man (1988)',\n",
       " '1179    Princess Bride, The (1987)',\n",
       " '1884    French Connection, The (1971)',\n",
       " '847    Godfather, The (1972)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "9dfdbvjqbcqguglc7w9a"
   },
   "source": [
    "Теперь ваша очередь реализовать самые популярные алгоритмы матричных разложений\n",
    "\n",
    "Что будет оцениваться:\n",
    "1. Корректность алгоритма\n",
    "2. Качество получившихся симиларов\n",
    "3. Качество итоговых рекомендаций для юзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellId": "n3rvli7z95c97xsz612p0a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cellId": "qh6gmuv5fca5oay7wzh07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellId": "kbrnzjlpvksq8yihrj8ck"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6041"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = list(set(ratings['user_id']))\n",
    "user_ids.sort()\n",
    "\n",
    "user_ids[0], user_ids[-1]\n",
    "\n",
    "N_USERS = user_ids[-1] + 1\n",
    "N_USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cellId": "0gm51teheysioqq4cmyndsb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3953"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ids = list(set(ratings['movie_id']))\n",
    "movie_ids.sort()\n",
    "\n",
    "movie_ids[0], movie_ids[-1]\n",
    "N_MOVIES = movie_ids[-1] + 1\n",
    "N_MOVIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "m49nt0owdenh19ip0spd28"
   },
   "source": [
    "### Задание 1. Не использую готовые решения, реализовать SVD разложение используя SGD на explicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cellId": "t7wqadb8spksqta3ftpx6d"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "ratings_sorted = ratings.sort_values(by=['timestamp'])\n",
    "\n",
    "n = len(ratings_sorted)\n",
    "train_size = int(n * 0.9)\n",
    "ratings_train = ratings_sorted.loc[:train_size]\n",
    "ratings_test  = ratings_sorted.loc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cellId": "i5cv2y3fyescorke65tj9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>900188</th>\n",
       "      <td>5443</td>\n",
       "      <td>1954</td>\n",
       "      <td>3</td>\n",
       "      <td>959980864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900028</th>\n",
       "      <td>5442</td>\n",
       "      <td>3728</td>\n",
       "      <td>4</td>\n",
       "      <td>959980872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900043</th>\n",
       "      <td>5443</td>\n",
       "      <td>590</td>\n",
       "      <td>4</td>\n",
       "      <td>959980892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900200</th>\n",
       "      <td>5443</td>\n",
       "      <td>1962</td>\n",
       "      <td>5</td>\n",
       "      <td>959980892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899991</th>\n",
       "      <td>5442</td>\n",
       "      <td>318</td>\n",
       "      <td>5</td>\n",
       "      <td>959980898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825793</th>\n",
       "      <td>4958</td>\n",
       "      <td>2399</td>\n",
       "      <td>1</td>\n",
       "      <td>1046454338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825438</th>\n",
       "      <td>4958</td>\n",
       "      <td>1407</td>\n",
       "      <td>5</td>\n",
       "      <td>1046454443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825724</th>\n",
       "      <td>4958</td>\n",
       "      <td>3264</td>\n",
       "      <td>4</td>\n",
       "      <td>1046454548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825731</th>\n",
       "      <td>4958</td>\n",
       "      <td>2634</td>\n",
       "      <td>3</td>\n",
       "      <td>1046454548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825603</th>\n",
       "      <td>4958</td>\n",
       "      <td>1924</td>\n",
       "      <td>4</td>\n",
       "      <td>1046454590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>915562 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating   timestamp\n",
       "900188     5443      1954       3   959980864\n",
       "900028     5442      3728       4   959980872\n",
       "900043     5443       590       4   959980892\n",
       "900200     5443      1962       5   959980892\n",
       "899991     5442       318       5   959980898\n",
       "...         ...       ...     ...         ...\n",
       "825793     4958      2399       1  1046454338\n",
       "825438     4958      1407       5  1046454443\n",
       "825724     4958      3264       4  1046454548\n",
       "825731     4958      2634       3  1046454548\n",
       "825603     4958      1924       4  1046454590\n",
       "\n",
       "[915562 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "ratings_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cellId": "ijfgojjrabo7uejrazvrf7"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "\n",
    "class SvdModel(nn.Module):\n",
    "    def __init__(self, n_u, n_v, alpha=1e-4):\n",
    "        super(SvdModel, self).__init__()\n",
    "        dim = 64\n",
    "        self.u = nn.Embedding(n_u, dim)\n",
    "        self.v = nn.Embedding(n_v, dim)\n",
    "        self.u_bias = nn.Embedding(n_u, 1)\n",
    "        self.v_bias = nn.Embedding(n_v, 1)\n",
    "        \n",
    "        scale = 1. / np.sqrt(dim)\n",
    "        nn.init.uniform_(self.u.weight, 0, scale)\n",
    "        nn.init.uniform_(self.v.weight, 0, scale)\n",
    "        nn.init.uniform_(self.u_bias.weight, 0, scale)\n",
    "        nn.init.uniform_(self.v_bias.weight, 0, scale)\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, u_idx, v_idx):\n",
    "        u_embedding = self.u(u_idx) + self.u_bias(u_idx)\n",
    "        v_embedding = self.v(v_idx) + self.v_bias(v_idx)\n",
    "        return (u_embedding * v_embedding).sum(dim=1)\n",
    "    \n",
    "    def reg(self, u_idx, v_idx):\n",
    "        u_norm = (self.u(u_idx) ** 2).sum(dim=1).mean()\n",
    "        v_norm = (self.v(v_idx) ** 2).sum(dim=1).mean()\n",
    "        return self.alpha * (v_norm + u_norm)\n",
    "\n",
    "class SvdRecomender:\n",
    "    def __init__(self, n_u, n_v, lr=0.01):\n",
    "        self.model = SvdModel(n_u, n_v, alpha=1e-3).to(device)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def fit(self, ratings, n_epoch=2000, batch_size=10000):\n",
    "        n = len(ratings)\n",
    "        print(type(ratings))\n",
    "        user_ids  = torch.tensor(ratings['user_id'].values, dtype=torch.long).to(device)\n",
    "        movie_ids = torch.tensor(ratings['movie_id'].values, dtype=torch.long).to(device)\n",
    "        r         = torch.tensor(ratings['rating'].values, dtype=torch.float).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "        perm = torch.randperm(n).to(device)\n",
    "        \n",
    "        for epoch in range(n_epoch):\n",
    "            optimizer.zero_grad()\n",
    "            losses = []\n",
    "            for l in range(0, n - batch_size, batch_size):\n",
    "                batch_idx = perm[l: l + batch_size]\n",
    "\n",
    "                u_idx = user_ids[batch_idx]\n",
    "                v_idx = movie_ids[batch_idx]\n",
    "                cur_r = r[batch_idx]\n",
    "                pred = self.model.forward(u_idx, v_idx)\n",
    "                loss = ((pred - cur_r) ** 2).mean() + self.model.reg(u_idx, v_idx)\n",
    "                loss.backward()\n",
    "                losses.append(loss.detach().item())\n",
    "            if epoch % 50 == 0:\n",
    "                print(f'epoch {epoch}/{n_epoch}')\n",
    "                print(f'average loss: {np.average(losses)}')\n",
    "                perm = torch.randperm(n).to(device)\n",
    "        \n",
    "            optimizer.step()\n",
    "        return self\n",
    "        \n",
    "    def predict(self, df):\n",
    "        user_ids  = torch.tensor(df['user_id'].values,  dtype=torch.long).to(device)\n",
    "        movie_ids = torch.tensor(df['movie_id'].values, dtype=torch.long).to(device)\n",
    "        \n",
    "        pred = self.model.forward(user_ids, movie_ids)\n",
    "        return pred.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cellId": "mlhb6l9wsoxww2d7m4cvp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "epoch 0/300\n",
      "average loss: 8.033027086257935\n",
      "epoch 50/300\n",
      "average loss: 0.8728708279132843\n",
      "epoch 100/300\n",
      "average loss: 0.8310353976488113\n",
      "epoch 150/300\n",
      "average loss: 0.8223923051357269\n",
      "epoch 200/300\n",
      "average loss: 0.8193404120206833\n",
      "epoch 250/300\n",
      "average loss: 0.8178995662927627\n"
     ]
    }
   ],
   "source": [
    "#!L\n",
    "model = SvdRecomender(N_USERS, N_MOVIES).fit(ratings, n_epoch=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "cellId": "99vdj7ilgzvwxpok771es"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2836    Sanjuro (1962)',\n",
       " '1950    Seven Samurai (The Magnificent Seven) (Shichin...',\n",
       " '315    Shawshank Redemption, The (1994)',\n",
       " '1162    Paths of Glory (1957)',\n",
       " '910    Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)',\n",
       " '49    Usual Suspects, The (1995)',\n",
       " '847    Godfather, The (1972)',\n",
       " '735    Close Shave, A (1995)',\n",
       " '1132    Wrong Trousers, The (1993)',\n",
       " '1194    Third Man, The (1949)']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "\n",
    "def recommend(user_id, model, k=10):\n",
    "    movie_ids = np.arange(N_MOVIES)\n",
    "    df = pd.DataFrame.from_dict({\n",
    "        'user_id' : np.repeat(user_id, len(movie_ids)),\n",
    "        'movie_id': movie_ids\n",
    "    })\n",
    "    r = model.predict(df)\n",
    "    \n",
    "    movies_seen = ratings[ratings['user_id'] == user_id]['movie_id']\n",
    "    movie_ids[movies_seen] = 0\n",
    "    movie_ids[0] = 0\n",
    "    \n",
    "    return r.argsort()[::-1][:k]\n",
    "\n",
    "movie_ids = recommend(4, model)\n",
    "\n",
    "[movie_info[movie_info[\"movie_id\"] == movie_id][\"name\"].to_string() for movie_id in movie_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "cellId": "uqlcdv1ui8oh487t16rvf7"
   },
   "outputs": [],
   "source": [
    "# TODO: figure out why it works soooo bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "cellId": "bbpy7o9d5xfqzyexerp6p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "epoch 0/300\n",
      "average loss: 8.367157816886902\n",
      "epoch 50/300\n",
      "average loss: 1.2411806136369705\n",
      "epoch 100/300\n",
      "average loss: 0.9616048112511635\n",
      "epoch 150/300\n",
      "average loss: 0.8883223757147789\n",
      "epoch 200/300\n",
      "average loss: 0.8583320528268814\n",
      "epoch 250/300\n",
      "average loss: 0.8433878794312477\n"
     ]
    }
   ],
   "source": [
    "#!L\n",
    "\n",
    "recomender = SvdRecomender(N_USERS, N_MOVIES).fit(ratings_train, n_epoch=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "cellId": "gd6axozp5eier140ta69ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9142395860581849"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "\n",
    "train_rmse = np.sqrt(np.average((recomender.predict(ratings_train) - ratings_train['rating'].values) ** 2))\n",
    "train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cellId": "7zk0xa0rpbwj83npphdei8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.334543001042999"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!L\n",
    "\n",
    "test_rmse = np.sqrt(np.average((recomender.predict(ratings_test) - ratings_test['rating'].values) ** 2))\n",
    "test_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "o1mty2c26t7whe3mo59jf8"
   },
   "source": [
    "### Задание 2. Не использую готовые решения, реализовать матричное разложение используя ALS на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "cellId": "hyjutlx4j92pysp61a1uq"
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import inv\n",
    "\n",
    "class AlsRecomender:\n",
    "    def __init__(self, n_u, n_v, alpha=1e-4):\n",
    "        self.dim = 64\n",
    "        self.U = None\n",
    "        self.V = None\n",
    "        self.n_u = n_u\n",
    "        self.n_v = n_v\n",
    "        self.alpha = 1e-4\n",
    "    \n",
    "    def fit(self, ratings, n_iters=100):\n",
    "        U = np.random.uniform(0, scale, size=[self.n_u, self.dim])\n",
    "        V = np.random.uniform(0, scale, size=[self.n_v, self.dim])\n",
    "        for i in range(n_iters):\n",
    "            # TODO fix the algorithm\n",
    "            \n",
    "            U_update = np.zeros_like(U)\n",
    "            V_inv = inv(np.dot(V.T, V) + self.alpha * np.eye(self.dim))\n",
    "            for user_id, movie_id in zip(ratings['user_id'], ratings['movie_id']):\n",
    "                U_update[user_id] += V_inv.dot(V[movie_id])\n",
    "            U = U_update\n",
    "             \n",
    "            V_update = np.zeros_like(V)\n",
    "            U_inv = inv(np.dot(U.T, U) + self.alpha * np.eye(self.dim))\n",
    "            for user_id, movie_id in zip(ratings['user_id'], ratings['movie_id']):\n",
    "                  V_update[movie_id] += U_inv.dot(U[user_id])\n",
    "            V = V_update\n",
    "        self.V = V\n",
    "        self.U = U\n",
    "        return self\n",
    "    \n",
    "    def predict(self, df):\n",
    "        user_ids  = ratings['user_id'].values\n",
    "        movie_ids = ratings['movie_id'].values\n",
    "        return self.U[user_ids] * self.V[movie_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "cellId": "yttc9qdbrhd6i1a0cofdzf"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "kwar45xdcsc3ui7luahmlr"
   },
   "source": [
    "### Задание 3. Не использую готовые решения, реализовать матричное разложение BPR на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "itfktwdku35ug95z56gjd"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vkp5lrwcupw4yq7c04c1f"
   },
   "source": [
    "### Задание 4. Не использую готовые решения, реализовать матричное разложение WARP на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3078z3276d3wx34hvqs5h"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "bcde7f5e-cd78-4b17-a998-fd807da78a40"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
